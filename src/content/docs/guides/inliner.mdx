---
title: Inliner
description: Run tasks on the main thread as an extra lane.
sidebar:
  order: 3
---

The `inliner` option adds the host (main thread) as one extra lane in the pool.
It helps distribute queued work across workers plus the host, instead of sending
everything to workers only.

```ts
const pool = createPool({
  threads: 4,
  inliner: { position: "last" },
})({ add });
```

:::note
The inliner is a lane, not a replacement for worker threads.
Use it to complement workers, not to avoid them.
:::

## Why It Exists

- It can reduce worker pressure by letting the host participate in execution.
- It can improve throughput for compute-style workloads when tasks are short and
  plentiful.
- It can reduce overhead for tiny tasks where crossing to worker threads is
  more expensive than local execution.

## How It Runs

Inline execution is not immediate in the `call.*()` path.
Calls are queued, then processed when the macro queue turn runs.

This delay is intentional: by that point, the dispatcher has had a chance to
send/receive worker tasks first, then the host drains inline work.

`batchSize` controls how many inline tasks run per macro-queue turn.

:::warning
Inline tasks run on the main thread. CPU-heavy work will block the event loop
(timers, I/O callbacks, HTTP handlers, etc.).
The macro-queue loop is useful, but not free.
:::

## Options

```ts
createPool({
  threads: number,
  inliner: {
    position?: "first" | "last",
    batchSize?: number,
  },
  balancer?: "robinRound" | "firstIdle" | "randomLane" | "firstIdleOrRandom",
})
```

### position

Controls where the inline lane appears relative to worker lanes.

- `"first"`: host lane is considered early.
- `"last"`: host lane is considered after workers.

For event-loop sensitive workloads (for example HTTP), `"last"` is usually safer.

### batchSize

Limits how many inline tasks are processed per macro-queue turn.

- Higher values are often good for maths/compute throughput.
- Lower values are usually better for HTTP/event-loop responsiveness.

If not set, it defaults to `1` when the inliner is enabled.

## Balancer Guidance

- For HTTP-style workloads:
  use `inliner.position: "last"` with `balancer: "firstIdle"` so workers are
  prioritized before the host lane.
- For pools with many registered tasks or uneven load:
  `randomLane` or `firstIdleOrRandom` can help spread pressure.

## When To Use It

- Compute-heavy and batch-oriented workloads (math pipelines, simulations).
- Bursty queues where one extra lane helps drain work.
- Tasks that are short enough that host participation is worth it.

## When Not To Use It

- Request/response HTTP hot paths where event-loop latency matters.
- Blocking tasks that can delay timers, sockets, or callbacks on the host.
- Cases where isolation is more important than squeezing one extra lane.

For many HTTP systems, separate pools per workload type is usually a better
choice than aggressive inlining.

## Current Limits

- There is no strategy yet for "use workers until threshold X, then efficiently
  wait on host lane."
- There is no built-in dynamic rebalance policy tied to event-loop pressure.

Those strategies are planned, so revisit your tuning as they land.

## Examples

### Compute-oriented

```ts
const { call, shutdown } = createPool({
  threads: 4,
  inliner: { position: "last", batchSize: 32 },
  balancer: "firstIdleOrRandom",
})({ scoreChunk });
```

### HTTP-friendly fallback

```ts
const { call, shutdown } = createPool({
  threads: 2,
  inliner: { position: "last" },
  balancer: "firstIdle",
})({ routeTask });
```
