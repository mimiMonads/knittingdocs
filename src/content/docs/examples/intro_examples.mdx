---
title: Introduction
description: Why these examples exist and what to copy into your own code.
sidebar:
  order: -1
---

These examples are practical reference patterns for using Knitting in real
workloads: CPU-heavy loops, batch scheduling, and data-transform pipelines.

## Why these examples matter

- They show when parallel work actually helps and when it does not.
- They demonstrate safe patterns for batching, pooling, and result aggregation.
- They keep correctness visible with reproducible inputs and validation checks.
- They map to real production tasks, not just toy computations.

## Example map

### Maths and simulation

- [Big prime](/examples/maths/Big_prime): long-running BigInt search with
  probabilistic testing.
- [Monte Carlo pi](/examples/maths/Monte_pi): embarrassingly parallel sampling
  and reduction.
- [Physics loop](/examples/maths/Physics_loop): branch-heavy simulation with
  per-chunk summaries.
- [TSP (GSA)](/examples/maths/Tsp_gsa): parallel heuristic restarts for NP-hard
  optimization.

### Data transforms

- [Data transforms topic carpet](/examples/data_transforms/intro_data_transforms):
  grouped navigation by validation and rendering topics.
- [Schema validate](/examples/data_transforms/validation/Schema_validate): parse
  JSON strings, validate against a schema, and return typed results.
- [Prompt token budgeting](/examples/data_transforms/validation/Prompt_token_budgeting):
  shape prompts and trim context before calling an LLM.
- [React SSR](/examples/data_transforms/rendering_output/React_ssr): parse,
  validate, transform, and render in workers.
- [React SSR compression](/examples/data_transforms/rendering_output/React_ssr_compress):
  compare where compression should run (worker vs host).
- [Markdown to HTML](/examples/data_transforms/rendering_output/Markdown_to_html):
  markdown rendering pipeline with host vs worker comparison.

## What to emulate from these examples

1. Keep worker tasks focused and deterministic.
2. Batch calls, then flush with `send()` to reduce scheduler overhead.
3. Return compact summaries from workers instead of large raw outputs.
4. Validate invariants on the host and recompute critical metrics when needed.
5. Compare against a host-only baseline before claiming speedups.
6. Tune chunk sizes and thread count based on throughput and stability.

If you copy these patterns, you get predictable behavior, easier debugging, and
better performance scaling.
