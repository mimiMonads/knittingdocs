---
title: React SSR compression
description: A practical SSR+compression example with a clear host-vs-worker benchmark.
hero:
  title: 'SSR + compression'
sidebar:
  order: 2

---

import { Tabs, TabItem } from '@astrojs/starlight/components';
import { Code } from '@astrojs/starlight/components';
import { getCode } from '../../../../../lib/code-snippets';
import DontDoubleParseTip from '../../../../../components/tips/DontDoubleParseTip.astro';

export const run = getCode("data_transforms/react_ssr_compress/run_ssr_compress.ts");
export const render_compress = getCode("data_transforms/react_ssr_compress/render_user_card_compressed.tsx");

## What is this about

This page has two parts:

1. A practical SSR+compression example (`run_ssr_compress.ts`).
2. A side-by-side benchmark using `--mode knitting` vs `--mode host`.

## Install

:::info
Bun
```bash
bun add react react-dom
```
:::

Compression uses the built-in `node:zlib` APIs (no extra packages required).

## Example command

Run this first to confirm the pipeline works end-to-end.

:::info
Bun
```bash
bun src/run_ssr_compress.ts --threads 2 --requests 1000 --mode knitting
```
Deno
```bash
deno run -A src/run_ssr_compress.ts --threads 2 --requests 1000 --mode knitting
```
Node
```bash
npx tsx src/run_ssr_compress.ts --threads 2 --requests 1000 --mode knitting
```
:::

## Benchmark commands

Then run both modes with the same request count and compare throughput.

:::info
Bun
```bash
bun src/run_ssr_compress.ts --threads 2 --requests 50000 --mode knitting
```
Host baseline (no workers)
```bash
bun src/run_ssr_compress.ts --requests 50000 --mode host
```
Deno
```bash
deno run -A src/run_ssr_compress.ts --threads 2 --requests 50000 --mode knitting
```
Host baseline (no workers)
```bash
deno run -A src/run_ssr_compress.ts --requests 50000 --mode host
```
Node
```bash
npx tsx src/run_ssr_compress.ts --threads 2 --requests 50000 --mode knitting
```
Host baseline (no workers)
```bash
npx tsx src/run_ssr_compress.ts --requests 50000 --mode host
```
:::

## What happens in this example

1. The host generates JSON payload strings.
2. In `--mode knitting`, payloads go to `renderUserCardCompressed` in workers.
3. Each worker parses JSON, renders SSR HTML, and compresses with Brotli.
4. In `--mode host`, the same work stays on the host.
5. The runner prints compressed bytes and throughput for both modes.

## What the benchmark measures

- `host`: parse + SSR + Brotli compress `N` requests on the main thread.
- `knitting`: run the same `N` requests through the pool and return compressed buffers.
- Worker mode includes serialization/deserialization of compressed output.
- `inliner.dispatchThreshold` keeps the host lane out at low load and joins on bursts.

<DontDoubleParseTip />


## Code

<Tabs>
  <TabItem label="run_ssr_compress.ts">
    <Code code={run} lang="ts" title={"run_ssr_compress.ts"} />
  </TabItem>
  <TabItem label="render_user_card_compressed.tsx">
    <Code code={render_compress} lang="tsx" title={"render_user_card_compressed.tsx"} />
  </TabItem>
</Tabs>

## Why this pattern matters

- It shows where compression fits in a realistic SSR pipeline.
- It makes transfer cost visible by returning compressed buffers.
- It gives a practical baseline before tuning inliner and thread counts.
